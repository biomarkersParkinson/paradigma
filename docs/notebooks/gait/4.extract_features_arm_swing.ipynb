{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting arm swing features\n",
    "The triaxial accelerometer, triaxial gyroscope, and (boolean) predictions of gait are used as input for extracting features relating to arm swing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tsdf\n",
    "\n",
    "from dbpd import DataColumns\n",
    "from dbpd.extracting_features import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell has the tag 'parameters'\n",
    "\n",
    "# paths and files\n",
    "path_to_data = '../../../tests/data/'\n",
    "input_path = os.path.join(path_to_data, '2.preprocessed_data', 'gait')\n",
    "output_path = os.path.join(path_to_data, '3.extracted_features', 'gait')\n",
    "\n",
    "# general\n",
    "sensor = 'IMU'\n",
    "units = 'degrees'\n",
    "sampling_frequency = 100\n",
    "\n",
    "time_colname = 'time'\n",
    "pred_gait_colname = 'pred_gait'\n",
    "angle_smooth_colname = 'angle_smooth'\n",
    "angle_colname = 'angle'\n",
    "velocity_colname = 'velocity'\n",
    "segment_nr_colname = 'segment_nr'\n",
    "\n",
    "# windowing\n",
    "window_type = 'hann'\n",
    "window_length_s = 3       # seconds\n",
    "window_overlap_s = 3*0.75    \n",
    "window_step_size_s = window_length_s - window_overlap_s\n",
    "\n",
    "l_data_point_level_cols = [\n",
    "    DataColumns.ACCELERATION_X,\n",
    "    DataColumns.ACCELERATION_Y,\n",
    "    DataColumns.ACCELERATION_Z,\n",
    "    DataColumns.ROTATION_X,\n",
    "    DataColumns.ROTATION_Y,\n",
    "    DataColumns.ROTATION_Z,\n",
    "    f'grav_{DataColumns.ACCELERATION_X}',\n",
    "    f'grav_{DataColumns.ACCELERATION_Y}',\n",
    "    f'grav_{DataColumns.ACCELERATION_Z}',\n",
    "    angle_smooth_colname, \n",
    "    velocity_colname\n",
    "]\n",
    "\n",
    "# computing power\n",
    "power_band_low_frequency = 0.3\n",
    "power_band_high_frequency = 3\n",
    "power_total_low_frequency = 0\n",
    "power_total_high_frequency = int(sampling_frequency / 2)\n",
    "\n",
    "d_frequency_bandwidths = {\n",
    "    'power_below_gait': [0.3, 0.7],\n",
    "    'power_gait': [0.7, 3.5],\n",
    "    'power_tremor': [3.5, 8],\n",
    "    'power_above_tremor': [8, sampling_frequency]\n",
    "}\n",
    "\n",
    "# cepstral coefficients\n",
    "cc_low_frequency = 0\n",
    "cc_high_frequency = int(sampling_frequency / 2) \n",
    "filter_length = 16\n",
    "n_dct_filters = 16\n",
    "\n",
    "d_channels_values = {\n",
    "    'angle_perc_power': 'proportion',\n",
    "    'range_of_motion': 'deg',\n",
    "    'forward_peak_ang_vel_mean': 'deg/s',\n",
    "    'forward_peak_ang_vel_std': 'deg/s',\n",
    "    'backward_peak_ang_vel_mean': 'deg/s',\n",
    "    'backward_peak_ang_vel_std': 'deg/s',\n",
    "    'std_norm_acc': 'g',\n",
    "    'grav_acceleration_x_mean': 'g',\n",
    "    'grav_acceleration_x_std': 'g',\n",
    "    'grav_acceleration_y_mean': 'g',\n",
    "    'grav_acceleration_y_std': 'g',\n",
    "    'grav_acceleration_z_mean': 'g',\n",
    "    'grav_acceleration_z_std': 'g',\n",
    "    'acceleration_x_power_below_gait': 'X', \n",
    "    'acceleration_x_power_gait': 'X',\n",
    "    'acceleration_x_power_tremor': 'X',\n",
    "    'acceleration_x_power_above_tremor': 'X',\n",
    "    'acceleration_x_dominant_frequency': 'Hz',\n",
    "    'acceleration_y_power_below_gait': 'X',\n",
    "    'acceleration_y_power_gait': 'X',\n",
    "    'acceleration_y_power_tremor': 'X',\n",
    "    'acceleration_y_power_above_tremor': 'X',\n",
    "    'acceleration_y_dominant_frequency': 'Hz',\n",
    "    'acceleration_z_power_below_gait': 'X',\n",
    "    'acceleration_z_power_gait': 'X',\n",
    "    'acceleration_z_power_tremor': 'X',\n",
    "    'acceleration_z_power_above_tremor': 'X',\n",
    "    'acceleration_z_dominant_frequency': 'Hz',\n",
    "    'rotation_x_dominant_frequency': 'Hz',\n",
    "    'rotation_y_dominant_frequency': 'Hz',\n",
    "    'rotation_z_dominant_frequency': 'Hz',\n",
    "    'cc_1_acceleration': 'X',\n",
    "    'cc_2_acceleration': 'X',\n",
    "    'cc_3_acceleration': 'X',\n",
    "    'cc_4_acceleration': 'X',\n",
    "    'cc_5_acceleration': 'X',\n",
    "    'cc_6_acceleration': 'X',\n",
    "    'cc_7_acceleration': 'X',\n",
    "    'cc_8_acceleration': 'X',\n",
    "    'cc_9_acceleration': 'X',\n",
    "    'cc_10_acceleration': 'X',\n",
    "    'cc_11_acceleration': 'X',\n",
    "    'cc_12_acceleration': 'X',\n",
    "    'cc_13_acceleration': 'X',\n",
    "    'cc_14_acceleration': 'X',\n",
    "    'cc_15_acceleration': 'X',\n",
    "    'cc_16_acceleration': 'X',\n",
    "    'cc_1_rotation': 'X',\n",
    "    'cc_2_rotation': 'X',\n",
    "    'cc_3_rotation': 'X',\n",
    "    'cc_4_rotation': 'X',\n",
    "    'cc_5_rotation': 'X',\n",
    "    'cc_6_rotation': 'X',\n",
    "    'cc_7_rotation': 'X',\n",
    "    'cc_8_rotation': 'X',\n",
    "    'cc_9_rotation': 'X',\n",
    "    'cc_10_rotation': 'X',\n",
    "    'cc_11_rotation': 'X',\n",
    "    'cc_12_rotation': 'X',\n",
    "    'cc_13_rotation': 'X',\n",
    "    'cc_14_rotation': 'X',\n",
    "    'cc_15_rotation': 'X',\n",
    "    'cc_16_rotation': 'X'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Number of rows doesn't match file length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     metadata_time \u001b[38;5;241m=\u001b[39m metadata_dict[time_filename]\n\u001b[1;32m     10\u001b[0m     metadata_samples \u001b[38;5;241m=\u001b[39m metadata_dict[values_filename]\n\u001b[0;32m---> 11\u001b[0m     l_dfs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtsdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataframe_from_binaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetadata_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_samples\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtsdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConcatenationType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(l_dfs[\u001b[38;5;241m0\u001b[39m], l_dfs[\u001b[38;5;241m1\u001b[39m], on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/git/biomarkers_repo/dbpd-toolbox/.venv/lib/python3.11/site-packages/tsdf/read_binary.py:31\u001b[0m, in \u001b[0;36mload_dataframe_from_binaries\u001b[0;34m(metadatas, concatenation)\u001b[0m\n\u001b[1;32m     29\u001b[0m data_frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metadata \u001b[38;5;129;01min\u001b[39;00m metadatas:\n\u001b[0;32m---> 31\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mload_ndarray_from_binary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data, columns\u001b[38;5;241m=\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mchannels)\n\u001b[1;32m     33\u001b[0m     data_frames\u001b[38;5;241m.\u001b[39mappend(df)\n",
      "File \u001b[0;32m~/git/biomarkers_repo/dbpd-toolbox/.venv/lib/python3.11/site-packages/tsdf/read_binary.py:58\u001b[0m, in \u001b[0;36mload_ndarray_from_binary\u001b[0;34m(metadata, start_row, end_row)\u001b[0m\n\u001b[1;32m     55\u001b[0m metadata_dir \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mfile_dir_path\n\u001b[1;32m     57\u001b[0m bin_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(metadata_dir, metadata\u001b[38;5;241m.\u001b[39mfile_name)\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_binary_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbin_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendianness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/biomarkers_repo/dbpd-toolbox/.venv/lib/python3.11/site-packages/tsdf/read_binary.py:112\u001b[0m, in \u001b[0;36m_load_binary_file\u001b[0;34m(bin_file_path, data_type, n_bits, endianness, n_rows, n_columns, start_row, end_row)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Check whether the number of rows matches the metadata\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m end_row \u001b[38;5;241m-\u001b[39m start_row:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of rows doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match file length.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[0;31mException\u001b[0m: Number of rows doesn't match file length."
     ]
    }
   ],
   "source": [
    "# load accelerometer and gyroscope data\n",
    "l_dfs = []\n",
    "for sensor in ['acceleration', 'gyroscope']:\n",
    "    meta_filename = f'{sensor}_meta.json'\n",
    "    values_filename = f'{sensor}_samples.bin'\n",
    "    time_filename = f'{sensor}_time.bin'\n",
    "\n",
    "    metadata_dict = tsdf.load_metadata_from_path(os.path.join(input_path, meta_filename))\n",
    "    metadata_time = metadata_dict[time_filename]\n",
    "    metadata_samples = metadata_dict[values_filename]\n",
    "    l_dfs.append(tsdf.load_dataframe_from_binaries([metadata_time, metadata_samples], tsdf.constants.ConcatenationType.columns))\n",
    "\n",
    "df = pd.merge(l_dfs[0], l_dfs[1], on='time')\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary add \"random\" predictions\n",
    "df[pred_gait_colname] = np.concatenate([np.repeat([1], df.shape[0]//3), np.repeat([0], df.shape[0]//3), np.repeat([1], df.shape[0] + 1 - 2*df.shape[0]//3)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[velocity_colname] = pca_transform_gyroscope(\n",
    "    df=df, \n",
    "    y_gyro_colname=DataColumns.ROTATION_Y,\n",
    "    z_gyro_colname=DataColumns.ROTATION_Z,\n",
    "    pred_gait_colname=pred_gait_colname\n",
    ")\n",
    "\n",
    "df[angle_colname] = compute_angle(\n",
    "    velocity_col=df[velocity_colname],\n",
    "    time_col=df[time_colname]\n",
    ")\n",
    "\n",
    "df[angle_smooth_colname] = remove_moving_average_angle(\n",
    "    angle_col=df[angle_colname],\n",
    "    sampling_frequency=sampling_frequency\n",
    ")\n",
    "\n",
    "df = df.loc[df[pred_gait_colname]==1].reset_index(drop=True)\n",
    "\n",
    "df_segments = create_segments(\n",
    "    df=df,\n",
    "    time_colname=time_colname,\n",
    "    segment_nr_colname='segment_nr',\n",
    "    minimum_gap_s=3\n",
    ")\n",
    "\n",
    "df_segments = discard_segments(\n",
    "    df=df_segments,\n",
    "    time_colname=time_colname,\n",
    "    segment_nr_colname='segment_nr',\n",
    "    minimum_segment_length_s=3\n",
    ")\n",
    "\n",
    "l_dfs = []\n",
    "for segment_nr in df_segments[segment_nr_colname].unique():\n",
    "    df_single_segment = df_segments.loc[df_segments[segment_nr_colname]==segment_nr].copy().reset_index(drop=True)\n",
    "    l_dfs.append(tabulate_windows(\n",
    "        df=df_single_segment,\n",
    "        time_column_name=time_colname,\n",
    "        segment_nr_colname=segment_nr_colname,\n",
    "        data_point_level_cols=l_data_point_level_cols,\n",
    "        window_length_s=window_length_s,\n",
    "        window_step_size_s=window_step_size_s,\n",
    "        segment_nr=segment_nr,\n",
    "        sampling_frequency=sampling_frequency,\n",
    "        )\n",
    "    )\n",
    "df_windowed = pd.concat(l_dfs).reset_index(drop=True)\n",
    "\n",
    "del df, df_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_windowed['angle_freqs'], df_windowed['angle_fft'] = signal_to_ffts(\n",
    "    sensor_col=df_windowed[angle_smooth_colname],\n",
    "    window_type=window_type,\n",
    "    sampling_frequency=sampling_frequency)\n",
    "\n",
    "df_windowed['rotation_dominant_frequency'] = df_windowed.apply(\n",
    "    lambda x: get_dominant_frequency(signal_ffts=x['angle_fft'],\n",
    "                                     signal_freqs=x['angle_freqs'],\n",
    "                                     fmin=power_band_low_frequency,\n",
    "                                     fmax=power_band_high_frequency\n",
    "                                     ), axis=1\n",
    ")\n",
    "\n",
    "df_windowed = df_windowed.drop(columns=['angle_fft', 'angle_freqs'])\n",
    "\n",
    "df_windowed['angle_perc_power'] = df_windowed[angle_smooth_colname].apply(\n",
    "    lambda x: compute_perc_power(\n",
    "        sensor_col=x,\n",
    "        fmin_band=power_band_low_frequency,\n",
    "        fmax_band=power_band_high_frequency,\n",
    "        fmin_total=power_total_low_frequency,\n",
    "        fmax_total=power_total_high_frequency,\n",
    "        sampling_frequency=sampling_frequency,\n",
    "        window_type=window_type\n",
    "        )\n",
    ")\n",
    "\n",
    "# note to eScience: why are the columns 'angle_new_minima', 'angle_new_maxima', \n",
    "# 'angle_minima_deleted' and 'angle_maxima deleted' created here? Should a copy\n",
    "# of 'df_windowed' be created inside 'extract_angle_extremes' to prevent this from\n",
    "# happening?\n",
    "extract_angle_extremes(\n",
    "    df=df_windowed,\n",
    "    smooth_angle_colname=angle_smooth_colname,\n",
    "    dominant_frequency_colname='rotation_dominant_frequency',\n",
    "    sampling_frequency=sampling_frequency\n",
    ")\n",
    "\n",
    "df_windowed = df_windowed.drop(columns=[angle_smooth_colname])\n",
    "\n",
    "df_windowed['angle_amplitudes'] = extract_range_of_motion(\n",
    "    angle_extrema_values_col=df_windowed['angle_extrema_values']\n",
    ")\n",
    "\n",
    "df_windowed = df_windowed.drop(columns=['angle_extrema_values'])\n",
    "\n",
    "df_windowed['range_of_motion'] = df_windowed['angle_amplitudes'].apply(lambda x: np.mean(x) if len(x) > 0 else 0).replace(np.nan, 0)\n",
    "\n",
    "df_windowed = df_windowed.drop(columns=['angle_amplitudes'])\n",
    "\n",
    "extract_peak_angular_velocity(\n",
    "    df=df_windowed,\n",
    "    velocity_colname=velocity_colname,\n",
    "    angle_minima_colname='angle_minima',\n",
    "    angle_maxima_colname='angle_maxima'\n",
    ")\n",
    "\n",
    "df_windowed = df_windowed.drop(columns=['angle_minima','angle_maxima', 'angle_new_minima',\n",
    "                                        'angle_new_maxima', velocity_colname])\n",
    "\n",
    "for dir in ['forward', 'backward']:\n",
    "    df_windowed[f'{dir}_peak_ang_vel_mean'] = df_windowed[f'{dir}_peak_ang_vel'].apply(lambda x: np.mean(x) if len(x) > 0 else 0)\n",
    "    df_windowed[f'{dir}_peak_ang_vel_std'] = df_windowed[f'{dir}_peak_ang_vel'].apply(lambda x: np.std(x) if len(x) > 0 else 0)\n",
    "\n",
    "    df_windowed = df_windowed.drop(columns=[f'{dir}_peak_ang_vel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_windowed['std_norm_acc'] = generate_std_norm(\n",
    "    df=df_windowed,\n",
    "    cols=[DataColumns.ACCELERATION_X, DataColumns.ACCELERATION_Y, DataColumns.ACCELERATION_Z]\n",
    ")\n",
    "\n",
    "for col in [x for x in df_windowed.columns if 'grav' in x]:\n",
    "    for stat in ['mean', 'std']:\n",
    "        df_windowed[f'{col}_{stat}'] = generate_statistics(\n",
    "            sensor_col=df_windowed[col],\n",
    "            statistic=stat\n",
    "        )\n",
    "\n",
    "for col in [DataColumns.ACCELERATION_X, DataColumns.ACCELERATION_Y, DataColumns.ACCELERATION_Z,\n",
    "            DataColumns.ROTATION_X, DataColumns.ROTATION_Y, DataColumns.ROTATION_Z]:\n",
    "    df_windowed[f'{col}_freqs'], df_windowed[f'{col}_fft'] = signal_to_ffts(\n",
    "        sensor_col=df_windowed[col],\n",
    "        window_type=window_type,\n",
    "        sampling_frequency=sampling_frequency\n",
    "    )\n",
    "\n",
    "    for bandwidth, frequencies in d_frequency_bandwidths.items():\n",
    "        df_windowed[col+'_'+bandwidth] = df_windowed[col].apply(\n",
    "            lambda x: compute_power_in_bandwidth(\n",
    "                sensor_col=x,\n",
    "                fmin=frequencies[0],\n",
    "                fmax=frequencies[1],\n",
    "                sampling_frequency=sampling_frequency,\n",
    "                window_type=window_type,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # dominant frequency\n",
    "    df_windowed[col+'_dominant_frequency'] = df_windowed.apply(\n",
    "        lambda x: get_dominant_frequency(\n",
    "            signal_ffts=x[col+'_fft'], \n",
    "            signal_freqs=x[col+'_freqs'],\n",
    "            fmin=power_total_low_frequency,\n",
    "            fmax=power_total_high_frequency\n",
    "        ), axis=1\n",
    "    )\n",
    "\n",
    "# cepstral coefficients\n",
    "for sensor in ['acceleration', 'gyroscope']:\n",
    "    if sensor == 'acceleration':\n",
    "        fft_cols = [f'{col}_fft' for col in [DataColumns.ACCELERATION_X, DataColumns.ACCELERATION_Y, DataColumns.ACCELERATION_Z]]\n",
    "    else:\n",
    "        fft_cols = [f'{col}_fft' for col in [DataColumns.ROTATION_X, DataColumns.ROTATION_Y, DataColumns.ROTATION_Z]]\n",
    "\n",
    "    df_windowed['total_power'] = compute_power(\n",
    "        df=df_windowed,\n",
    "        fft_cols=fft_cols\n",
    "    )\n",
    "\n",
    "    cc_cols = generate_cepstral_coefficients(\n",
    "        total_power_col=df_windowed['total_power'],\n",
    "        window_length_s=window_length_s,\n",
    "        sampling_frequency=sampling_frequency,\n",
    "        low_frequency=power_total_low_frequency,\n",
    "        high_frequency=power_total_high_frequency,\n",
    "        filter_length=filter_length,\n",
    "        n_dct_filters=n_dct_filters\n",
    "    )\n",
    "\n",
    "    df_windowed = pd.concat([df_windowed, cc_cols], axis=1)\n",
    "\n",
    "    for i in range(n_dct_filters):\n",
    "        df_windowed = df_windowed.rename(columns={f'cc_{i+1}': f'cc_{i+1}_{sensor}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_drop_cols = [DataColumns.ACCELERATION_X, DataColumns.ACCELERATION_Y, DataColumns.ACCELERATION_Z,\n",
    "               DataColumns.ROTATION_X, DataColumns.ROTATION_Y, DataColumns.ROTATION_Z,\n",
    "              f'grav_{DataColumns.ACCELERATION_X}', f'grav_{DataColumns.ACCELERATION_Y}', f'grav_{DataColumns.ACCELERATION_Z}',\n",
    "              f'{DataColumns.ACCELERATION_X}_fft', f'{DataColumns.ACCELERATION_Y}_fft', f'{DataColumns.ACCELERATION_Z}_fft',\n",
    "              f'{DataColumns.ROTATION_X}_fft', f'{DataColumns.ROTATION_Y}_fft', f'{DataColumns.ROTATION_Z}_fft',\n",
    "              f'{DataColumns.ACCELERATION_X}_freqs', f'{DataColumns.ACCELERATION_Y}_freqs', f'{DataColumns.ACCELERATION_Z}_freqs',\n",
    "              f'{DataColumns.ROTATION_X}_freqs', f'{DataColumns.ROTATION_Y}_freqs', f'{DataColumns.ROTATION_Z}_freqs',\n",
    "              f'{DataColumns.ACCELERATION_X}_fft_power', f'{DataColumns.ACCELERATION_Y}_fft_power', f'{DataColumns.ACCELERATION_Z}_fft_power',\n",
    "                f'{DataColumns.ROTATION_X}_fft_power', f'{DataColumns.ROTATION_Y}_fft_power', f'{DataColumns.ROTATION_Z}_fft_power',\n",
    "              'total_power', 'rotation_dominant_frequency', 'window_nr', 'window_end']\n",
    "\n",
    "df_windowed = df_windowed.drop(columns=l_drop_cols).rename(columns={'window_start': 'time'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "import datetime\n",
    "\n",
    "end_iso8601 = (parser.parse(metadata_samples.start_iso8601) + datetime.timedelta(seconds=int(df_windowed['time'][-1:].values[0] + window_length_s))).strftime('%d-%b-%Y %H:%M:%S') + ' UTC'\n",
    "\n",
    "metadata_samples.__setattr__('end_iso8601', end_iso8601)\n",
    "metadata_samples.__setattr__('file_name', 'arm_swing_values.bin')\n",
    "metadata_samples.__setattr__('file_dir_path', output_path)\n",
    "metadata_time.__setattr__('end_iso8601', end_iso8601)\n",
    "metadata_time.__setattr__('file_name', 'arm_swing_time.bin')\n",
    "metadata_time.__setattr__('file_dir_path', output_path)\n",
    "\n",
    "metadata_samples.__setattr__('channels', list(d_channels_values.keys()))\n",
    "metadata_samples.__setattr__('units', list(d_channels_values.values()))\n",
    "metadata_samples.__setattr__('data_type', np.float32)\n",
    "metadata_samples.__setattr__('bits', 32)\n",
    "\n",
    "metadata_time.__setattr__('channels', ['time'])\n",
    "metadata_time.__setattr__('units', ['relative_time_ms'])\n",
    "metadata_time.__setattr__('data_type', np.int32)\n",
    "metadata_time.__setattr__('bits', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# store binaries and metadata\n",
    "tsdf.write_dataframe_to_binaries(output_path, df_windowed, [metadata_time, metadata_samples])\n",
    "tsdf.write_metadata([metadata_time, metadata_samples], 'arm_swing_meta.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
