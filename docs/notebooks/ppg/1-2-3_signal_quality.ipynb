{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main script to perform heart rate estimation of wearable imu\n",
    "\n",
    "This script uses both PPG and accelerometer and performs the following steps:\n",
    "1. Loading all metadata of PPG and IMU\n",
    "2. Query on data availability + synchronization\n",
    "3. Loading relevant segment sensor data using tsdf wrapper (start for loop over synchronized segment indices)\n",
    "4. Synchronize the data (correct indices etc)\n",
    "5. Data preprocessing\n",
    "6. Feature extraction\n",
    "7. Classification\n",
    "\n",
    "\n",
    "## Architecture overview\n",
    "The script implements the following steps:\n",
    " - Step 1: IMU and PPG preprocessing\n",
    " - Step 2: IMU and PPG feature extraction\n",
    " - Step 3: Signal quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "import tsdf\n",
    "import dbpd\n",
    "from dbpd import DataColumns\n",
    "from dbpd.ppg_preprocessing import tsdf_scan_meta, synchronization, extract_overlapping_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell has the tag 'parameters'\n",
    "path_to_data =  '../../../tests/data'\n",
    "\n",
    "input_path_imu = os.path.join(path_to_data, '1.sensor_data', 'imu')\n",
    "input_path_ppg = os.path.join(path_to_data, '1.sensor_data', 'ppg')\n",
    "output_path = os.path.join(path_to_data, '2.preprocessed_data', 'ppg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "sensor_imu = 'IMU'\n",
    "sensor_ppg = 'PPG'\n",
    "\n",
    "imu_meta_filename = f'{sensor_imu}_meta.json'\n",
    "imu_values_filename = f'{sensor_imu}_samples.bin'\n",
    "imu_time_filename = f'{sensor_imu}_time.bin'\n",
    "\n",
    "ppg_meta_filename = f'{sensor_ppg}_meta.json'\n",
    "ppg_values_filename = f'{sensor_ppg}_samples.bin'\n",
    "ppg_time_filename = f'{sensor_ppg}_time.bin'\n",
    "\n",
    "no_units = 'none'\n",
    "acceleration_units = 'm/s^2'\n",
    "\n",
    "d_channels_units_imu = {\n",
    "    DataColumns.ACCELEROMETER_X: acceleration_units,\n",
    "    DataColumns.ACCELEROMETER_Y: acceleration_units,\n",
    "    DataColumns.ACCELEROMETER_Z: acceleration_units\n",
    "}\n",
    "\n",
    "d_channels_units_ppg = {\n",
    "    DataColumns.PPG: no_units\n",
    "}\n",
    "\n",
    "# filtering\n",
    "# sampling_frequency = 100\n",
    "# lower_cutoff_frequency = 0.3\n",
    "# filter_order = 4\n",
    "\n",
    "# Constants\n",
    "UNIX_TICKS_MS = 1000.0\n",
    "FS_PPG = 30  # Sampling rate for PPG\n",
    "FS_IMU = 100  # Sampling rate for IMU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading all metadata of PPG and IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_ppg = tsdf_scan_meta(input_path_ppg)\n",
    "meta_imu = tsdf_scan_meta(input_path_imu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Query on data availability + synchronization\n",
    "\n",
    "Calculate PPG and IMU segments that describe the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '2021-06-27T16:52:20Z' does not match format '%d-%b-%Y %H:%M:%S %Z'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m segment_ppg, segment_imu \u001b[38;5;241m=\u001b[39m \u001b[43msynchronization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta_ppg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_imu\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Define `synchronization`\u001b[39;00m\n",
      "File \u001b[0;32m~/git/biomarkers_repo/dbpd-toolbox/src/dbpd/ppg_preprocessing.py:88\u001b[0m, in \u001b[0;36msynchronization\u001b[0;34m(ppg_meta, imu_meta)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mSynchronize PPG and IMU data segments based on their start and end times.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    List of synchronized segment indices for IMU data.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m ppg_start_time \u001b[38;5;241m=\u001b[39m [convert_iso8601_to_datetime(t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_iso8601\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ppg_meta]\n\u001b[0;32m---> 88\u001b[0m imu_start_time \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mconvert_iso8601_to_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_iso8601\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimu_meta\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     89\u001b[0m ppg_end_time \u001b[38;5;241m=\u001b[39m [convert_iso8601_to_datetime(t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_iso8601\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ppg_meta]\n\u001b[1;32m     90\u001b[0m imu_end_time \u001b[38;5;241m=\u001b[39m [convert_iso8601_to_datetime(t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_iso8601\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m imu_meta]\n",
      "File \u001b[0;32m~/git/biomarkers_repo/dbpd-toolbox/src/dbpd/ppg_preprocessing.py:88\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mSynchronize PPG and IMU data segments based on their start and end times.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    List of synchronized segment indices for IMU data.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m ppg_start_time \u001b[38;5;241m=\u001b[39m [convert_iso8601_to_datetime(t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_iso8601\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ppg_meta]\n\u001b[0;32m---> 88\u001b[0m imu_start_time \u001b[38;5;241m=\u001b[39m [\u001b[43mconvert_iso8601_to_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_iso8601\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m imu_meta]\n\u001b[1;32m     89\u001b[0m ppg_end_time \u001b[38;5;241m=\u001b[39m [convert_iso8601_to_datetime(t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_iso8601\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ppg_meta]\n\u001b[1;32m     90\u001b[0m imu_end_time \u001b[38;5;241m=\u001b[39m [convert_iso8601_to_datetime(t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_iso8601\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m imu_meta]\n",
      "File \u001b[0;32m~/git/biomarkers_repo/dbpd-toolbox/src/dbpd/ppg_preprocessing.py:67\u001b[0m, in \u001b[0;36mconvert_iso8601_to_datetime\u001b[0;34m(date_str)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_iso8601_to_datetime\u001b[39m(date_str):\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m        Convert a date string to a datetime object.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m        datetime.datetime(2021, 6, 27, 16, 52, 20, tzinfo=<UTC>)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mb-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mZ\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    566\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    347\u001b[0m found \u001b[38;5;241m=\u001b[39m format_regex\u001b[38;5;241m.\u001b[39mmatch(data_string)\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n",
      "\u001b[0;31mValueError\u001b[0m: time data '2021-06-27T16:52:20Z' does not match format '%d-%b-%Y %H:%M:%S %Z'"
     ]
    }
   ],
   "source": [
    "segment_ppg, segment_imu = synchronization(meta_ppg, meta_imu)  # Define `synchronization`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading relevant segment sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0  # Assuming we're only looking at the first synchronized segment pair - the loop here should be over all segment pairs\n",
    "meta_path_ppg = meta_ppg[segment_ppg[n]]['tsdf_meta_fullpath']\n",
    "meta_path_imu = meta_imu[segment_imu[n]]['tsdf_meta_fullpath']\n",
    "\n",
    "metadata_list_ppg = tsdf.load_metadata_from_path(meta_path_ppg)\n",
    "metadata_list_imu = tsdf.load_metadata_from_path(meta_path_imu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PPG data\n",
    "metadata_time_ppg = metadata_list_ppg[ppg_time_filename]\n",
    "metadata_samples_ppg = metadata_list_ppg[ppg_values_filename]\n",
    "df_ppg = tsdf.load_dataframe_from_binaries([metadata_time_ppg, metadata_samples_ppg], tsdf.constants.ConcatenationType.columns)\n",
    "\n",
    "# Load IMU data\n",
    "metadata_time_imu = metadata_list_imu[imu_time_filename]\n",
    "metadata_samples_imu = metadata_list_imu[imu_values_filename]\n",
    "df_imu = tsdf.load_dataframe_from_binaries([metadata_time_imu, metadata_samples_imu], tsdf.constants.ConcatenationType.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>649511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.959961</td>\n",
       "      <td>648214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time   green\n",
       "0  0.000000  649511\n",
       "1  9.959961  648214"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ppg.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>accelerometer_x</th>\n",
       "      <th>accelerometer_y</th>\n",
       "      <th>accelerometer_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1151</td>\n",
       "      <td>1200</td>\n",
       "      <td>-572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.040039</td>\n",
       "      <td>-1120</td>\n",
       "      <td>1303</td>\n",
       "      <td>-532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  accelerometer_x  accelerometer_y  accelerometer_z\n",
       "0   0.000000            -1151             1200             -572\n",
       "1  10.040039            -1120             1303             -532"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the gyroscope columns from the IMU data\n",
    "cols_to_drop = df_imu.filter(regex='^rotation_').columns\n",
    "df_imu.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "df_imu = df_imu.rename(columns={f'acceleration_{a}': f'accelerometer_{a}' for a in ['x', 'y', 'z']})\n",
    "\n",
    "df_imu.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>accelerometer_x</th>\n",
       "      <th>accelerometer_y</th>\n",
       "      <th>accelerometer_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72945</th>\n",
       "      <td>1.624806e+09</td>\n",
       "      <td>-502</td>\n",
       "      <td>-1075</td>\n",
       "      <td>-1689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72946</th>\n",
       "      <td>1.624806e+09</td>\n",
       "      <td>-509</td>\n",
       "      <td>-1068</td>\n",
       "      <td>-1689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time  accelerometer_x  accelerometer_y  accelerometer_z\n",
       "72945  1.624806e+09             -502            -1075            -1689\n",
       "72946  1.624806e+09             -509            -1068            -1689"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dbpd.constants import DataColumns, TimeUnit\n",
    "\n",
    "# Extract indices for time and samples (TSDF should support extracting data based on the channel names)\n",
    "time_idx_ppg = metadata_list_ppg[\"PPG_time.bin\"]\n",
    "time_idx_imu = metadata_list_imu[\"IMU_time.bin\"]\n",
    "values_idx_ppg = metadata_list_ppg[\"PPG_samples.bin\"]\n",
    "values_idx_imu = metadata_list_imu[\"IMU_samples.bin\"]\n",
    "\n",
    "start_time_ppg = datetime.strptime(time_idx_ppg.start_iso8601, '%d-%b-%Y %H:%M:%S %Z').timestamp()\n",
    "df_imu[DataColumns.TIME] = dbpd.imu_preprocessing.transform_time_array(\n",
    "    time_array=df_imu[DataColumns.TIME],\n",
    "    scale_factor=1000, \n",
    "    input_unit_type = TimeUnit.difference_ms,\n",
    "    output_unit_type = TimeUnit.absolute_ms,\n",
    "    start_time = start_time_ppg)\n",
    "\n",
    "start_time_imu = datetime.strptime(time_idx_imu.start_iso8601, '%d-%b-%Y %H:%M:%S %Z').timestamp()\n",
    "df_ppg[DataColumns.TIME] = dbpd.imu_preprocessing.transform_time_array(\n",
    "    time_array=df_ppg[DataColumns.TIME],\n",
    "    scale_factor=1000, \n",
    "    input_unit_type = TimeUnit.difference_ms,\n",
    "    output_unit_type = TimeUnit.absolute_ms,\n",
    "    start_time = start_time_imu)\n",
    "\n",
    "\n",
    "df_imu.tail(2)\n",
    "# ts_ppg = int(datetime_ppg.timestamp() * UNIX_TICKS_MS)\n",
    "# ts_imu = int(datetime_imu.timestamp() * UNIX_TICKS_MS)\n",
    "\n",
    "# # Calculating continuous time vectors\n",
    "# t_ppg = np.cumsum(data_list_ppg[time_idx_ppg]) + ts_ppg\n",
    "# t_imu = np.cumsum(data_list_imu[time_idx_imu]) + ts_imu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data synchronization on right indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the original data: (64775, 2) (72947, 4)\n",
      "Shape of the overlapping segments: (64775, 2) (64361, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the original data:\", df_ppg.shape, df_imu.shape)\n",
    "\n",
    "# Extract overlapping segments\n",
    "df_ppg_overlapping, df_imu_overlapping = extract_overlapping_segments(df_ppg, df_imu)\n",
    "\n",
    "print(\"Shape of the overlapping segments:\", df_ppg_overlapping.shape, df_imu_overlapping.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of unscaled_column_names:  <class 'list'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# df_imu_proc = dbpd.imu_preprocessing.resample_data(\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     time_abs_array=np.array(df_imu_overlapping[DataColumns.TIME]),\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     values_unscaled=np.array(df_imu_overlapping[list(d_channels_units_imu.keys())]),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# metadata_samples_ppg.scale_factors - they do not exist always\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m df_ppg_proc \u001b[38;5;241m=\u001b[39m \u001b[43mdbpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimu_preprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_ppg_overlapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDataColumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTIME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43munscaled_column_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md_channels_units_ppg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale_factors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_samples_imu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_factors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresampling_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFS_PPG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_time_imu\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# v_ppg_pre, tr_ppg_pre = preprocessing_ppg(v_ppg, FS_PPG)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# v_imu_pre, tr_imu_pre = preprocessing_imu(v_imu, FS_IMU)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# TODO: Save preprocessed data and compare with the expected results\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# location = \"../../tests/data/2.preprocessed_data/ppg\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# save_preprocessed_data(v_ppg_pre, tr_ppg_pre, v_imu_pre, tr_imu_pre, location)\u001b[39;00m\n",
      "File \u001b[0;32m~/git/biomarkers_repo/dbpd-toolbox/src/dbpd/imu_preprocessing.py:104\u001b[0m, in \u001b[0;36mresample_data\u001b[0;34m(df, time_column, unscaled_column_names, resampling_frequency, scale_factors, start_time)\u001b[0m\n\u001b[1;32m    101\u001b[0m     scaled_values \u001b[38;5;241m=\u001b[39m values_unscaled \u001b[38;5;241m*\u001b[39m scale_factors\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# resample\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m t_resampled \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_abs_array\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresampling_frequency\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# create dataframe\u001b[39;00m\n\u001b[1;32m    107\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(t_resampled, columns\u001b[38;5;241m=\u001b[39m[time_column])\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'type'"
     ]
    }
   ],
   "source": [
    "# The following method is failing\n",
    "df_imu_proc = dbpd.imu_preprocessing.resample_data(\n",
    "    time_abs_array=np.array(df_imu_overlapping[DataColumns.TIME]),\n",
    "    values_unscaled=np.array(df_imu_overlapping[list(d_channels_units_imu.keys())]),\n",
    "    scale_factors=metadata_samples_imu.scale_factors[0:3],\n",
    "    resampling_frequency=FS_IMU,\n",
    "    time_column=DataColumns.TIME)\n",
    "\n",
    "# metadata_samples_ppg.scale_factors - the data specifies 1, but it is not an obligatory tsdf field, maybe it should be optional parameter in `resample_data`\n",
    "df_ppg_proc = dbpd.imu_preprocessing.resample_data(\n",
    "    df=df_ppg_overlapping,\n",
    "    time_column=DataColumns.TIME,\n",
    "    time_unit_type=TimeUnit.absolute_ms,\n",
    "    unscaled_column_names = list(d_channels_units_ppg.keys()),\n",
    "    scale_factors=metadata_samples_imu.scale_factors,\n",
    "    resampling_frequency=FS_PPG,\n",
    "    start_time = start_time_imu\n",
    "    )\n",
    "\n",
    "df_imu_proc = dbpd.imu_preprocessing.resample_data(\n",
    "    df=df_imu_overlapping,\n",
    "    time_column=DataColumns.TIME,\n",
    "    time_unit_type=TimeUnit.absolute_ms,\n",
    "    unscaled_column_names = list(d_channels_units_imu.keys()),\n",
    "    scale_factors=metadata_samples_imu.scale_factors,\n",
    "    resampling_frequency=FS_IMU,\n",
    "    start_time = start_time_imu\n",
    "    )\n",
    "\n",
    "# Still TODO\n",
    "# use the same sampling frequency for both PPG and IMU to test whether the resampling works (the shape should be the same)\n",
    "# v_ppg_pre, tr_ppg_pre = preprocessing_ppg(v_ppg, FS_PPG)\n",
    "# v_imu_pre, tr_imu_pre = preprocessing_imu(v_imu, FS_IMU)\n",
    "\n",
    "# TODO: Save preprocessed data and compare with the expected results\n",
    "# location = \"../../tests/data/2.preprocessed_data/ppg\"\n",
    "# save_preprocessed_data(v_ppg_pre, tr_ppg_pre, v_imu_pre, tr_imu_pre, location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Feature extraction and Classification\n",
    "# Assume feature extraction and classification functions are implemented\n",
    "# features_ppg, features_imu = extract_features(v_ppg_pre, v_imu_pre)\n",
    "# classification_results = classify_signals(features_ppg, features_imu)\n",
    "\n",
    "# Save the classification results\n",
    "# save_classification_data(classification_results, location)\n",
    "\n",
    "# We need to implement:\n",
    "# - synchronization: to find overlapping segments between PPG and IMU data based on metadata\n",
    "# - extract_overlapping_segments: to calculate the correct indices for synchronized data segments\n",
    "# - preprocessing_ppg, preprocessing_imu: functions to preprocess the raw PPG and IMU data\n",
    "# - extract_features: to extract relevant features from the preprocessed data\n",
    "# - classify_signals: to perform the classification on the extracted features\n",
    "# - save_preprocessed_data, save_classification_data: functions to save data to files in a suitable format\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
