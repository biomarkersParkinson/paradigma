{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main script to perform heart rate estimation of wearable PPG\n",
    "\n",
    "This script uses both PPG and accelerometer and performs the following steps:\n",
    "1. Loading all metadata of PPG and IMU\n",
    "2. Query on data availability + synchronization\n",
    "3. Loading relevant segment sensor data using tsdf wrapper (start for loop over synchronized segment indices)\n",
    "4. Synchronize the data (correct indices etc)\n",
    "5. Data preprocessing\n",
    "6. Feature extraction\n",
    "7. Classification\n",
    "\n",
    "\n",
    "## Architecture overview\n",
    "The script implements the following steps:\n",
    " - Step 1: IMU and PPG preprocessing\n",
    " - Step 2: IMU and PPG feature extraction\n",
    " - Step 3: Signal quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Automatically reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "import tsdf\n",
    "import dbpd\n",
    "\n",
    "# Import your tsdf handling library, assumed to be written by you\n",
    "# from tsdf_handler import tsdf_scan_meta, load_tsdf_metadata_from_path, tsdf_values_idx, load_ndarray_from_binary, save_tsdf_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module methods\n",
    "\n",
    "def tsdf_scan_meta(tsdf_data_full_path : str) -> List[dict]:\n",
    "    \"\"\"\n",
    "    For each given TSDF directory, transcribe TSDF metadata contents to a list of dictionaries.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tsdf_data_full_path : str\n",
    "        Full path to the directory containing TSDF metadata files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[Dict]\n",
    "        List of dictionaries with metadata from each JSON file in the directory.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> tsdf_scan_meta('/path/to/tsdf_data')\n",
    "    [{'start_iso8601': '2021-06-27T16:52:20Z', 'end_iso8601': '2021-06-27T17:52:20Z'}, ...]\n",
    "    \"\"\"\n",
    "    tsdf = []\n",
    "    \n",
    "    # Collect all metadata JSON files in the specified directory\n",
    "    meta_list = list(Path(tsdf_data_full_path).rglob('*_meta.json'))\n",
    "    for meta_file in meta_list:\n",
    "        with open(meta_file, 'r') as file:\n",
    "            json_obj = json.load(file)\n",
    "            meta_data = {\n",
    "                'tsdf_meta_fullpath': str(meta_file),\n",
    "                'subject_id': json_obj['subject_id'],\n",
    "                'start_iso8601': json_obj['start_iso8601'],\n",
    "                'end_iso8601': json_obj['end_iso8601']\n",
    "            }\n",
    "            tsdf.append(meta_data)\n",
    "    \n",
    "    return tsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "UNIX_TICKS_MS = 1000.0\n",
    "FS_PPG = 30  # Sampling rate for PPG\n",
    "FS_IMU = 100  # Sampling rate for IMU\n",
    "\n",
    "# Paths\n",
    "raw_data_root = '../../../tests/data/1.sensor_data/'\n",
    "ppp_data_path_ppg = os.path.join(raw_data_root, 'PPG')\n",
    "ppp_data_path_imu = os.path.join(raw_data_root, 'IMU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Loading all metadata of PPG and IMU\n",
    "\n",
    "meta_ppg = tsdf_scan_meta(ppp_data_path_ppg)\n",
    "meta_imu = tsdf_scan_meta(ppp_data_path_imu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "def convert_iso8601_to_datetime(date_str):\n",
    "        \"\"\"\n",
    "        Convert a date string to a datetime object.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        date_str : str\n",
    "            Date string in the format '%d-%b-%Y %H:%M:%S %Z'.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        datetime\n",
    "            A datetime object corresponding to the input date string.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> convert_to_datetime('27-Jun-2021 16:52:20 UTC')\n",
    "        datetime.datetime(2021, 6, 27, 16, 52, 20, tzinfo=<UTC>)\n",
    "        \"\"\"\n",
    "        return datetime.strptime(date_str, '%d-%b-%Y %H:%M:%S %Z')\n",
    "\n",
    "def synchronization(ppg_meta, imu_meta):\n",
    "    \"\"\"\n",
    "    Synchronize PPG and IMU data segments based on their start and end times.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ppg_meta : list of dict\n",
    "        List of dictionaries containing 'start_iso8601' and 'end_iso8601' keys for PPG data.\n",
    "    imu_meta : list of dict\n",
    "        List of dictionaries containing 'start_iso8601' and 'end_iso8601' keys for IMU data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    segment_ppg_total : list of int\n",
    "        List of synchronized segment indices for PPG data.\n",
    "    segment_imu_total : list of int\n",
    "        List of synchronized segment indices for IMU data.\n",
    "    \"\"\"\n",
    "    ppg_start_time = [convert_iso8601_to_datetime(t['start_iso8601']) for t in ppg_meta]\n",
    "    imu_start_time = [convert_iso8601_to_datetime(t['start_iso8601']) for t in imu_meta]\n",
    "    ppg_end_time = [convert_iso8601_to_datetime(t['end_iso8601']) for t in ppg_meta]\n",
    "    imu_end_time = [convert_iso8601_to_datetime(t['end_iso8601']) for t in imu_meta]\n",
    "\n",
    "    # Create a time vector covering the entire range\n",
    "    time_vector_total = []\n",
    "    current_time = min(min(ppg_start_time), min(imu_start_time))\n",
    "    end_time = max(max(ppg_end_time), max(imu_end_time))\n",
    "    while current_time <= end_time:\n",
    "        time_vector_total.append(current_time)\n",
    "        current_time += timedelta(seconds=1)\n",
    "    \n",
    "    time_vector_total = np.array(time_vector_total)\n",
    "\n",
    "    # Initialize variables\n",
    "    data_presence_ppg = np.zeros(len(time_vector_total), dtype=int)\n",
    "    data_presence_ppg_idx = np.zeros(len(time_vector_total), dtype=int)\n",
    "    data_presence_imu = np.zeros(len(time_vector_total), dtype=int)\n",
    "    data_presence_imu_idx = np.zeros(len(time_vector_total), dtype=int)\n",
    "\n",
    "    # Mark the segments of PPG data with 1\n",
    "    for i, (start, end) in enumerate(zip(ppg_start_time, ppg_end_time)):\n",
    "        indices = np.where((time_vector_total >= start) & (time_vector_total < end))[0]\n",
    "        data_presence_ppg[indices] = 1\n",
    "        data_presence_ppg_idx[indices] = i\n",
    "\n",
    "    # Mark the segments of IMU data with 1\n",
    "    for i, (start, end) in enumerate(zip(imu_start_time, imu_end_time)):\n",
    "        indices = np.where((time_vector_total >= start) & (time_vector_total < end))[0]\n",
    "        data_presence_imu[indices] = 1\n",
    "        data_presence_imu_idx[indices] = i\n",
    "\n",
    "    # Find the indices where both PPG and IMU data are present\n",
    "    corr_indices = np.where((data_presence_ppg == 1) & (data_presence_imu == 1))[0]\n",
    "\n",
    "    # Find the start and end indices of each segment\n",
    "    corr_start_end = []\n",
    "    if len(corr_indices) > 0:\n",
    "        start_idx = corr_indices[0]\n",
    "        for i in range(1, len(corr_indices)):\n",
    "            if corr_indices[i] - corr_indices[i - 1] > 1:\n",
    "                end_idx = corr_indices[i - 1]\n",
    "                corr_start_end.append((start_idx, end_idx))\n",
    "                start_idx = corr_indices[i]\n",
    "        # Add the last segment\n",
    "        corr_start_end.append((start_idx, corr_indices[-1]))\n",
    "\n",
    "    # Extract the synchronized indices for each segment\n",
    "    segment_ppg_total = []\n",
    "    segment_imu_total = []\n",
    "    for start_idx, end_idx in corr_start_end:\n",
    "        segment_ppg = np.unique(data_presence_ppg_idx[start_idx:end_idx + 1])\n",
    "        segment_imu = np.unique(data_presence_imu_idx[start_idx:end_idx + 1])\n",
    "        if len(segment_ppg) > 1 and len(segment_imu) == 1:\n",
    "            segment_ppg_total.extend(segment_ppg)\n",
    "            segment_imu_total.extend([segment_imu[0]] * len(segment_ppg))\n",
    "        elif len(segment_ppg) == 1 and len(segment_imu) > 1:\n",
    "            segment_ppg_total.extend([segment_ppg[0]] * len(segment_imu))\n",
    "            segment_imu_total.extend(segment_imu)\n",
    "        elif len(segment_ppg) == len(segment_imu):\n",
    "            segment_ppg_total.extend(segment_ppg)\n",
    "            segment_imu_total.extend(segment_imu)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return segment_ppg_total, segment_imu_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Query on data availability + synchronization\n",
    "segment_ppg, segment_imu = synchronization(meta_ppg, meta_imu)  # Define `synchronization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../tests/data/1.sensor_data/PPG/PPG_meta.json\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tsdf_values_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m metadata_list_imu \u001b[38;5;241m=\u001b[39m tsdf\u001b[38;5;241m.\u001b[39mload_metadata_from_path(meta_path_imu)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# metadata_list_ppg, data_list_ppg = tsdf.load_metadata_from_path(meta_path_ppg)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# metadata_list_imu, data_list_imu = tsdf.load_metadata_from_path(meta_path_imu)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Extract indices for time and samples\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m time_idx_ppg \u001b[38;5;241m=\u001b[39m \u001b[43mtsdf_values_idx\u001b[49m(metadata_list_ppg, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m time_idx_imu \u001b[38;5;241m=\u001b[39m tsdf_values_idx(metadata_list_imu, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m values_idx_ppg \u001b[38;5;241m=\u001b[39m tsdf_values_idx(metadata_list_ppg, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tsdf_values_idx' is not defined"
     ]
    }
   ],
   "source": [
    "# 3. Loading relevant segment sensor data\n",
    "n = 0  # Assuming we're only looking at the first synchronized segment\n",
    "meta_path_ppg = meta_ppg[segment_ppg[n]]['tsdf_meta_fullpath']\n",
    "meta_path_imu = meta_imu[segment_imu[n]]['tsdf_meta_fullpath']\n",
    "print(meta_path_ppg)\n",
    "\n",
    "metadata_list_ppg = tsdf.load_metadata_from_path(meta_path_ppg)\n",
    "metadata_list_imu = tsdf.load_metadata_from_path(meta_path_imu)\n",
    "\n",
    "# metadata_list_ppg, data_list_ppg = tsdf.load_metadata_from_path(meta_path_ppg)\n",
    "# metadata_list_imu, data_list_imu = tsdf.load_metadata_from_path(meta_path_imu)\n",
    "\n",
    "# Extract indices for time and samples\n",
    "time_idx_ppg = tsdf_values_idx(metadata_list_ppg, 'time')\n",
    "time_idx_imu = tsdf_values_idx(metadata_list_imu, 'time')\n",
    "values_idx_ppg = tsdf_values_idx(metadata_list_ppg, 'samples')\n",
    "values_idx_imu = tsdf_values_idx(metadata_list_imu, 'samples')\n",
    "\n",
    "# Process time data\n",
    "datetime_ppg = datetime.strptime(metadata_list_ppg[time_idx_ppg]['start_iso8601'], '%d-%b-%Y %H:%M:%S %Z')\n",
    "datetime_imu = datetime.strptime(metadata_list_imu[time_idx_imu]['start_iso8601'], '%d-%b-%Y %H:%M:%S %Z')\n",
    "\n",
    "ts_ppg = int(datetime_ppg.timestamp() * UNIX_TICKS_MS)\n",
    "ts_imu = int(datetime_imu.timestamp() * UNIX_TICKS_MS)\n",
    "\n",
    "# Calculating continuous time vectors\n",
    "t_ppg = np.cumsum(data_list_ppg[time_idx_ppg]) + ts_ppg\n",
    "t_imu = np.cumsum(data_list_imu[time_idx_imu]) + ts_imu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data synchronization on right indices\n",
    "ppg_indices, imu_indices = extract_overlapping_segments(t_ppg, t_imu)  # Define this function\n",
    "\n",
    "# Update data vectors based on synchronized indices\n",
    "v_ppg = data_list_ppg[values_idx_ppg][ppg_indices[0]:ppg_indices[1]]\n",
    "v_imu = data_list_imu[values_idx_imu][imu_indices[0]:imu_indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'synchronization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m meta_imu \u001b[38;5;241m=\u001b[39m tsdf_scan_meta(ppp_data_path_imu)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 2. Query on data availability + synchronization\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m segment_ppg, segment_imu \u001b[38;5;241m=\u001b[39m \u001b[43msynchronization\u001b[49m(meta_ppg, meta_imu)  \u001b[38;5;66;03m# Define `synchronization`\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 3. Loading relevant segment sensor data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Assuming we're only looking at the first synchronized segment\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'synchronization' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Data preprocessing\n",
    "# Implement `preprocessing_ppg` and `preprocessing_imu` to suit your data format\n",
    "v_ppg_pre, tr_ppg_pre = preprocessing_ppg(v_ppg, FS_PPG)\n",
    "v_imu_pre, tr_imu_pre = preprocessing_imu(v_imu, FS_IMU)\n",
    "\n",
    "# Save preprocessed data\n",
    "location = \"../../tests/data/2.preprocessed_data/ppg\"\n",
    "save_preprocessed_data(v_ppg_pre, tr_ppg_pre, v_imu_pre, tr_imu_pre, location)\n",
    "\n",
    "# Feature extraction and Classification\n",
    "# Assume feature extraction and classification functions are implemented\n",
    "features_ppg, features_imu = extract_features(v_ppg_pre, v_imu_pre)\n",
    "classification_results = classify_signals(features_ppg, features_imu)\n",
    "\n",
    "# Save the classification results\n",
    "save_classification_data(classification_results, location)\n",
    "\n",
    "# We need to implement:\n",
    "# - synchronization: to find overlapping segments between PPG and IMU data based on metadata\n",
    "# - extract_overlapping_segments: to calculate the correct indices for synchronized data segments\n",
    "# - preprocessing_ppg, preprocessing_imu: functions to preprocess the raw PPG and IMU data\n",
    "# - extract_features: to extract relevant features from the preprocessed data\n",
    "# - classify_signals: to perform the classification on the extracted features\n",
    "# - save_preprocessed_data, save_classification_data: functions to save data to files in a suitable format\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
