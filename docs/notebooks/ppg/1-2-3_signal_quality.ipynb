{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main script to perform heart rate estimation of wearable PPG\n",
    "\n",
    "This script uses both PPG and accelerometer and performs the following steps:\n",
    "1. Loading all metadata of PPG and IMU\n",
    "2. Query on data availability + synchronization\n",
    "3. Loading relevant segment sensor data using tsdf wrapper (start for loop over synchronized segment indices)\n",
    "4. Synchronize the data (correct indices etc)\n",
    "5. Data preprocessing\n",
    "6. Feature extraction\n",
    "7. Classification\n",
    "\n",
    "\n",
    "## Architecture overview\n",
    "The script implements the following steps:\n",
    " - Step 1: IMU and PPG preprocessing\n",
    " - Step 2: IMU and PPG feature extraction\n",
    " - Step 3: Signal quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "import tsdf\n",
    "import dbpd\n",
    "\n",
    "# Import your tsdf handling library, assumed to be written by you\n",
    "# from tsdf_handler import tsdf_scan_meta, load_tsdf_metadata_from_path, tsdf_values_idx, load_ndarray_from_binary, save_tsdf_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module methods\n",
    "\n",
    "def tsdf_scan_meta(tsdf_data_full_path):\n",
    "    \"\"\"\n",
    "    For each given TSDF directory, transcribe TSDF metadata contents to a list of dictionaries.\n",
    "    This function is specific for a toolbox data structure mimicking the given MATLAB code.\n",
    "    \n",
    "    Parameters:\n",
    "    - tsdf_data_full_path: Full path to the directory containing TSDF metadata files.\n",
    "    \n",
    "    Returns:\n",
    "    - tsdf: List of dictionaries with metadata from each JSON file in the directory.\n",
    "    \"\"\"\n",
    "    tsdf = []\n",
    "    \n",
    "    # Collect all metadata JSON files in the specified directory\n",
    "    meta_list = list(Path(tsdf_data_full_path).rglob('*_meta.json'))\n",
    "    for meta_file in meta_list:\n",
    "        with open(meta_file, 'r') as file:\n",
    "            json_obj = json.load(file)\n",
    "            meta_data = {\n",
    "                'tsdf_meta_fullpath': str(meta_file),\n",
    "                'subject_id': json_obj['subject_id'],\n",
    "                'start_iso8601': json_obj['start_iso8601'],\n",
    "                'end_iso8601': json_obj['end_iso8601']\n",
    "            }\n",
    "            tsdf.append(meta_data)\n",
    "    \n",
    "    return tsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "UNIX_TICKS_MS = 1000.0\n",
    "FS_PPG = 30  # Sampling rate for PPG\n",
    "FS_IMU = 100  # Sampling rate for IMU\n",
    "\n",
    "# Paths\n",
    "raw_data_root = '../../../tests/data/1.sensor_data/'\n",
    "ppp_data_path_ppg = os.path.join(raw_data_root, 'PPG')\n",
    "ppp_data_path_imu = os.path.join(raw_data_root, 'IMU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Loading all metadata of PPG and IMU\n",
    "meta_ppg = tsdf_scan_meta(ppp_data_path_ppg)\n",
    "meta_imu = tsdf_scan_meta(ppp_data_path_imu)\n",
    "\n",
    "# 2. Query on data availability + synchronization\n",
    "segment_ppg, segment_imu = synchronization(meta_ppg, meta_imu)  # Define `synchronization`\n",
    "\n",
    "# 3. Loading relevant segment sensor data\n",
    "n = 1  # Assuming we're only looking at the first synchronized segment\n",
    "meta_path_ppg = meta_ppg[segment_ppg[n]].tsdf_meta_fullpath\n",
    "meta_path_imu = meta_imu[segment_imu[n]].tsdf_meta_fullpath\n",
    "\n",
    "metadata_list_ppg, data_list_ppg = load_tsdf_metadata_from_path(meta_path_ppg)\n",
    "metadata_list_imu, data_list_imu = load_tsdf_metadata_from_path(meta_path_imu)\n",
    "\n",
    "# Extract indices for time and samples\n",
    "time_idx_ppg = tsdf_values_idx(metadata_list_ppg, 'time')\n",
    "time_idx_imu = tsdf_values_idx(metadata_list_imu, 'time')\n",
    "values_idx_ppg = tsdf_values_idx(metadata_list_ppg, 'samples')\n",
    "values_idx_imu = tsdf_values_idx(metadata_list_imu, 'samples')\n",
    "\n",
    "# Process time data\n",
    "datetime_ppg = datetime.strptime(metadata_list_ppg[time_idx_ppg]['start_iso8601'], '%d-%b-%Y %H:%M:%S %Z')\n",
    "datetime_imu = datetime.strptime(metadata_list_imu[time_idx_imu]['start_iso8601'], '%d-%b-%Y %H:%M:%S %Z')\n",
    "\n",
    "ts_ppg = int(datetime_ppg.timestamp() * UNIX_TICKS_MS)\n",
    "ts_imu = int(datetime_imu.timestamp() * UNIX_TICKS_MS)\n",
    "\n",
    "# Calculating continuous time vectors\n",
    "t_ppg = np.cumsum(data_list_ppg[time_idx_ppg]) + ts_ppg\n",
    "t_imu = np.cumsum(data_list_imu[time_idx_imu]) + ts_imu\n",
    "\n",
    "# 4. Data synchronization on right indices\n",
    "ppg_indices, imu_indices = extract_overlapping_segments(t_ppg, t_imu)  # Define this function\n",
    "\n",
    "# Update data vectors based on synchronized indices\n",
    "v_ppg = data_list_ppg[values_idx_ppg][ppg_indices[0]:ppg_indices[1]]\n",
    "v_imu = data_list_imu[values_idx_imu][imu_indices[0]:imu_indices[1]]\n",
    "\n",
    "# 5. Data preprocessing\n",
    "# Implement `preprocessing_ppg` and `preprocessing_imu` to suit your data format\n",
    "v_ppg_pre, tr_ppg_pre = preprocessing_ppg(v_ppg, FS_PPG)\n",
    "v_imu_pre, tr_imu_pre = preprocessing_imu(v_imu, FS_IMU)\n",
    "\n",
    "# Save preprocessed data\n",
    "location = \"../../tests/data/2.preprocessed_data/ppg\"\n",
    "save_preprocessed_data(v_ppg_pre, tr_ppg_pre, v_imu_pre, tr_imu_pre, location)\n",
    "\n",
    "# Feature extraction and Classification\n",
    "# Assume feature extraction and classification functions are implemented\n",
    "features_ppg, features_imu = extract_features(v_ppg_pre, v_imu_pre)\n",
    "classification_results = classify_signals(features_ppg, features_imu)\n",
    "\n",
    "# Save the classification results\n",
    "save_classification_data(classification_results, location)\n",
    "\n",
    "# You need to implement:\n",
    "# - synchronization: to find overlapping segments between PPG and IMU data based on metadata\n",
    "# - extract_overlapping_segments: to calculate the correct indices for synchronized data segments\n",
    "# - preprocessing_ppg, preprocessing_imu: functions to preprocess the raw PPG and IMU data\n",
    "# - extract_features: to extract relevant features from the preprocessed data\n",
    "# - classify_signals: to perform the classification on the extracted features\n",
    "# - save_preprocessed_data, save_classification_data: functions to save data to files in a suitable format\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
