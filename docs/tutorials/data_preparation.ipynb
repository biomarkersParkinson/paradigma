{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "ParaDigMa requires the sensor data to be of a specific format. This tutorial provides examples of how to prepare your input data for subsequent analysis. In the end, the input for ParaDigMa is a dataframe consisting of:\n",
    "* A time column representing the seconds relative to the first row of the dataframe;\n",
    "* One or multiple of the following sensor column categories:\n",
    "  * Triaxial accelerometer (x, y, z) in _g_\n",
    "  * Triaxial gyroscope (x, y, z) in _deg/s_\n",
    "  * Photoplethysmography (PPG) \n",
    "\n",
    "The final dataframe should be resampled to 100 Hz, have the correct units for the sensor columns, and the correct format for the time column. Also note that the _gait_ pipeline expects a specific orientation of sensor axes, as explained in [Coordinate system](../guides/coordinate_system)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from paradigma.constants import TimeUnit\n",
    "from paradigma.util import load_tsdf_dataframe, transform_time_array, convert_units_accelerometer, \\\n",
    "    convert_units_gyroscope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "This example uses data of the [Personalized Parkinson Project](https://pubmed.ncbi.nlm.nih.gov/31315608/), which is stored in Time Series Data Format (`TSDF`). Inertial Measurements Units (IMU) and photoplethysmography (PPG) data are sampled at a different sampling frequency and therefore stored separately. Note that ParaDigMa works independent of data storage format; it only requires a `pandas.DataFrame` as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_raw_data = Path('../../tests/data/data_preparation_tutorial')\n",
    "path_to_imu_data = path_to_raw_data / 'imu'\n",
    "\n",
    "df_imu, imu_time, imu_values = load_tsdf_dataframe(\n",
    "    path_to_data=path_to_imu_data, \n",
    "    prefix='IMU'\n",
    ")\n",
    "\n",
    "df_imu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_ppg_data = os.path.join(path_to_raw_data, 'ppg')\n",
    "\n",
    "df_ppg, ppg_time, ppg_values = load_tsdf_dataframe(\n",
    "    path_to_data=path_to_ppg_data, \n",
    "    prefix='PPG'\n",
    ")\n",
    "\n",
    "df_ppg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timestamps in this dataset correspond to delta milliseconds, and the data is not uniformly distributed as can be observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set column names\n",
    "You are free to choose column names, although we recommend using the column names set in ParaDigMa for convenience in subsequent data processing steps. These are accessible through the class [`DataColumns`](https://biomarkersparkinson.github.io/paradigma/autoapi/paradigma/constants/index.html#paradigma.constants.DataColumns), which can be imported from [`paradigma.constants`](https://biomarkersparkinson.github.io/paradigma/autoapi/paradigma/constants/index.html). For example, we recommend setting `acc_x_colname` to `DataColumns.ACCELEROMETER_X`. Again, this is not strictly necessary for future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_colname = 'time'  # DataColumns.TIME\n",
    "\n",
    "acc_x_colname = 'accelerometer_x'  # DataColumns.ACCELEROMETER_X\n",
    "acc_y_colname = 'accelerometer_y'  # DataColumns.ACCELEROMETER_Y\n",
    "acc_z_colname = 'accelerometer_z'  # DataColumns.ACCELEROMETER_Z\n",
    "gyr_x_colname = 'gyroscope_x'  # DataColumns.GYROSCOPE_X\n",
    "gyr_y_colname = 'gyroscope_y'  # DataColumns.GYROSCOPE_Y\n",
    "gyr_z_colname = 'gyroscope_z'  # DataColumns.GYROSCOPE_Z\n",
    "\n",
    "ppg_colname = 'green'  # DataColumns.PPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change units\n",
    "ParaDigMa expects acceleration to be measured in g, and rotation in deg/s. Units can be converted conveniently using ParaDigMa functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to units of the sampled data\n",
    "accelerometer_units = 'm/s^2'\n",
    "gyroscope_units = 'deg/s'\n",
    "\n",
    "# State the column names\n",
    "accelerometer_columns = [acc_x_colname, acc_y_colname, acc_z_colname]\n",
    "gyroscope_columns = [gyr_x_colname, gyr_y_colname, gyr_z_colname]\n",
    "\n",
    "accelerometer_data = df_imu[accelerometer_columns].values\n",
    "gyroscope_data = df_imu[gyroscope_columns].values\n",
    "\n",
    "# Convert units to expected format\n",
    "df_imu[accelerometer_columns] = convert_units_accelerometer(\n",
    "    data=accelerometer_data, \n",
    "    units=accelerometer_units\n",
    ")\n",
    "df_imu[gyroscope_columns] = convert_units_gyroscope(\n",
    "    data=gyroscope_data, \n",
    "    units=gyroscope_units\n",
    ")\n",
    "\n",
    "df_imu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Account for watch side\n",
    "For the Gait & Arm Swing pipeline, it is essential to ensure correct sensor axes orientation. For more information please read [Coordinate System](../guides/coordinate_system) and set the axes of the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the orientation of the sensor according to the documented coordinate system. \n",
    "# The following changes are specific to the used sensor and its orientation \n",
    "# relative to predefined coordinate system.\n",
    "df_imu[acc_y_colname] *= -1\n",
    "df_imu[acc_z_colname] *= -1\n",
    "df_imu[gyr_y_colname] *= -1\n",
    "df_imu[gyr_z_colname] *= -1\n",
    "\n",
    "df_imu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change time column\n",
    "ParaDigMa expects the data to be in seconds relative to the first row, which should be equal to 0. The toolbox has the built-in function [`transform_time_array`](https://biomarkersparkinson.github.io/paradigma/autoapi/paradigma/util/index.html#paradigma.util.transform_time_array) to help users transform their time column to the correct format if the timestamps have been sampled in delta time between timestamps. In the near future, the functionalities for transforming other types (e.g., datetime format) shall be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imu[time_colname] = transform_time_array(\n",
    "    time_array=df_imu[time_colname], \n",
    "    input_unit_type=TimeUnit.DIFFERENCE_MS, \n",
    "    output_unit_type=TimeUnit.RELATIVE_S,\n",
    ")\n",
    "\n",
    "df_imu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppg[time_colname] = transform_time_array(\n",
    "    time_array=df_ppg[time_colname], \n",
    "    input_unit_type=TimeUnit.DIFFERENCE_MS, \n",
    "    output_unit_type=TimeUnit.RELATIVE_S,\n",
    ")\n",
    "\n",
    "df_ppg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These dataframes are ready to be processed by ParaDigMa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on Non-Contiguous Data\n",
    "\n",
    "If your data has gaps or interruptions (e.g., battery died, device removed, multiple recording sessions), you have two options:\n",
    "\n",
    "### Option 1: Auto-segmentation (Recommended)\n",
    "Use the `split_by_gaps=True` parameter in `run_paradigma()`:\n",
    "\n",
    "```python\n",
    "from paradigma.orchestrator import run_paradigma\n",
    "\n",
    "results = run_paradigma(\n",
    "    dfs=df_prepared,\n",
    "    pipelines='gait',\n",
    "    watch_side='left',\n",
    "    split_by_gaps=True,             # Automatically handle gaps\n",
    "    max_gap_seconds=1.5,            # Split on gaps > 1.5s\n",
    "    min_segment_seconds=2.0,        # Discard segments < 2s\n",
    ")\n",
    "```\n",
    "\n",
    "This will:\n",
    "- Automatically detect and split data at gaps larger than `max_gap_seconds`\n",
    "- Discard segments shorter than `min_segment_seconds`\n",
    "- Process each contiguous segment independently\n",
    "- Add a `data_segment_nr` column to track recording chunks\n",
    "\n",
    "### Option 2: Manual segmentation\n",
    "Create segments yourself using functions from [segmenting.py](../../src/paradigma/segmenting.py):\n",
    "\n",
    "```python\n",
    "from paradigma.segmenting import create_segments, discard_segments\n",
    "\n",
    "# Create segments based on time gaps\n",
    "df_prepared['data_segment_nr'] = create_segments(\n",
    "    time_array=df_prepared['time'].values,\n",
    "    max_segment_gap_s=1.5\n",
    ")\n",
    "\n",
    "# Optionally discard short segments\n",
    "df_prepared = discard_segments(\n",
    "    df=df_prepared,\n",
    "    segment_nr_colname='data_segment_nr',\n",
    "    min_segment_length_s=2.0,\n",
    "    fs=100,  # sampling frequency\n",
    "    format='timestamps'\n",
    ")\n",
    "\n",
    "# Then run paradigma normally (split_by_gaps=False)\n",
    "results = run_paradigma(\n",
    "    dfs=df_prepared,\n",
    "    pipelines='gait',\n",
    "    watch_side='left',\n",
    "    split_by_gaps=False  # Data already segmented\n",
    ")\n",
    "```\n",
    "\n",
    "For more details and examples, see the [Pipeline Orchestrator Tutorial](https://biomarkersparkinson.github.io/paradigma/tutorials/pipeline_orchestrator.html#auto-segmentation-for-non-contiguous-data)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
